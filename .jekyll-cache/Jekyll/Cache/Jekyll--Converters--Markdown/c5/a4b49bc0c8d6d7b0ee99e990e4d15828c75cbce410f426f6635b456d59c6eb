I"…<p>As a lab, we‚Äôre interested in natural behaviors. This can mean a lot of things, but in particular, it means attempting to study human and animal behavior the way it occurs outside the lab. Many of the tools we build harness modern computing to enable us to do this with the precision and rigor of traditional lab experiments.</p>

<p>In our <a href="https://pearsonlab.github.io/blog/2015/11/06/eye_tracking_tech.html">previous attempts</a> at extracting gaze location from a dynamic video and mapping it back to static objects, we were fairly conservative in that we did not attempt to view the target object from a skewed angle, and we ensured that the entire object was in the video frame at all times. It‚Äôs a fairly simple application that nonetheless touches on some fairly clever pieces of computer vision.</p>

<p>More recently, though, we‚Äôve been exploring a new use case that raises all sorts of intriguing complexities: the act of viewing a work of art.</p>

<p>When we look at a painting, for example, we are typically ‚Äúdoing more‚Äù than what we might do when recognizing an image of a platypus or a car on a computer screen. Lots of writing in the humanities tries to understand what this ‚Äúdoing more‚Äù entails, but at the very least, it encompasses our patterns of gaze (what we look at and in what order) and the dynamics of our bodies in space (where we stand and the perspective from which we look). What‚Äôs more, artists themselves have long contemplated these same aspects of the viewing process and created works designed to interact with, engage, and surprise us as we look.</p>

<p>So if works of art are objects meant to provoke rich and unique patterns of looking, why not study this process?</p>

<p>In collaboration with <a href="https://dibs.duke.edu/scholars/elizabeth-johnson">Zab Johnson</a>‚Äôs lab and with curator Marianne Wardle of Duke‚Äôs <a href="http://emuseum.nasher.duke.edu/">Nasher Museum</a>, we‚Äôve been doing just that. Thanks to our eye tracking glasses, we‚Äôre able to let people view works in the Nasher‚Äôs galleries while we track where they‚Äôre looking. But unlike most lab experiments that have people look at static images, we‚Äôre able to let them explore the works in the way they naturally would ‚Äî approaching the work from across the room, leaning in close to study details, studying from all angles.</p>

<p>Yet we needed to make sure that we could still map gaze points from close up and extreme angles back to a static image of the piece of art. And this presents an additional challenge, since only a portion of the work is visible in the eye tracker‚Äôs camera at any moment.</p>

<p>So how‚Äôd we do? An example of our technique applied to a single frame:</p>

<table class="image">
<caption align="bottom"><font size="1">Wangechi Mutu, Family Tree, 2012. One of 13 mixed-media collages on paper, 14 1/8 √ó 10 3/16 in. (35.9 √ó 25.9 cm). Collection of the Nasher Museum. Museum purchase with additional funds provided by Trent Carmichael (T‚Äô88, P‚Äô17), Blake Byrne (T'57), Marjorie and Michael Levine (T‚Äô84, P‚Äô16, P‚Äô19, P‚Äô19), Stefanie and Douglas Kahn (P‚Äô11, P‚Äô13), and Christen and Derek Wilson (T'86, B'90, P'15). c Wangechi Mutu.</font></caption>
<tr><td><img class="img-responsive" src="http://people.duke.edu/~sni/mutu1.jpg" alt="Wangechi Mutu, Family Tree, 2012. One of 13 mixed-media collages on paper, 14 1/8 √ó 10 3/16 in. (35.9 √ó 25.9 cm). Collection of the Nasher Museum. Museum purchase with additional funds provided by Trent Carmichael (T‚Äô88, P‚Äô17), Blake Byrne (T'57), Marjorie and Michael Levine (T‚Äô84, P‚Äô16, P‚Äô19, P‚Äô19), Stefanie and Douglas Kahn (P‚Äô11, P‚Äô13), and Christen and Derek Wilson (T'86, B'90, P'15). c Wangechi Mutu." width="50%" /></td></tr>
</table>

<p>We take a match image like this one and try to find it in a video frame.</p>

<table class="image">
<caption align="bottom"><font size="1"></font></caption>
<tr><td><img class="img-responsive" src="http://people.duke.edu/~sni/video_frame.png" alt="" width="50%" /></td></tr>
</table>

<p>We then select a box from that video frame to transform to the match image‚Äôs dimensions.</p>

<table class="image">
<caption align="bottom"><font size="1"></font></caption>
<tr><td><img class="img-responsive" src="http://people.duke.edu/~sni/transformed.png" alt="" width="50%" /></td></tr>
</table>

<p>The perspective transform is important because we also apply that same transformation to gaze location points in order to get the gaze location on the static image.</p>

<p>With this technique, we can now use traditional analysis methods from eye tracking to compare viewing patterns across individuals by first mapping back to the reference image. We can also begin to think about the role viewing angle and space play in these gaze patterns by using camera angles and zoom to calculate distance from the works as patrons explored.</p>

<p>More on this to come. In the meantime, check out the results when we apply this to a full video:</p>

<div class="video-container">
<iframe width="730" height="410" src="https://www.youtube.com/embed/fSl6FiyHTes?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen=""></iframe>
</div>
<p><br /></p>

<p>Links to pages on the Nasher Museum site for the works included:</p>

<ul>
  <li><a href="http://emuseum.nasher.duke.edu/view/objects/asitem/items$0040:18231">Wangechi Mutu, Family Tree, 2012</a></li>
  <li><a href="http://emuseum.nasher.duke.edu/view/objects/asitem/items$0040:14671">Jeff Sonhouse, Decompositioning, 2010</a></li>
</ul>
:ET